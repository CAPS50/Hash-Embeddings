{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:00:14.871142Z",
     "start_time": "2018-01-14T14:00:14.861467Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from hashembed.embedding import HashEmbedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:01:04.580180Z",
     "start_time": "2018-01-14T14:01:03.809373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10fb780f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "num_classes = len(categories)\n",
    "\n",
    "# constants\n",
    "use_hash_embeddings = False\n",
    "embedding_size = 20\n",
    "num_buckets = 5000\n",
    "max_words = 10**6\n",
    "max_epochs = 10\n",
    "num_hash_functions = 2\n",
    "hidden = 50 \n",
    "seed = 3\n",
    "batchSize = 32 # default in keras\n",
    "size_phrase = 150\n",
    "isMasking = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "weights1 = [np.random.normal(scale = 0.05, size = (max_words,embedding_size))]\n",
    "weights2 = [np.random.normal(scale = 0.05, size = (embedding_size,hidden)).T, np.zeros((hidden))]\n",
    "weights3 = [np.random.normal(scale = 0.05, size = (hidden,num_classes)).T, np.zeros((num_classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:02:37.902788Z",
     "start_time": "2018-01-14T14:02:37.893644Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_encoder(w, max_idx):\n",
    "    # v = hash(w) #\n",
    "    v = int(hashlib.sha1(w.encode('utf-8')).hexdigest(), 16)\n",
    "    return (v % (max_idx-1)) + 1\n",
    "\n",
    "def ReduceSum(x,m):\n",
    "    return torch.sum(x,dim=1)\n",
    "\n",
    "def param_from_np(array, requires_grad=True, astype=torch.FloatTensor):\n",
    "    return torch.nn.Parameter(torch.from_numpy(array).type(astype),requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:02:38.146628Z",
     "start_time": "2018-01-14T14:02:38.039890Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelSimple(nn.Module):\n",
    "    def __init__(self,max_words,embedding_size,num_classes,hidden=hidden,seed=3,isMasking=isMasking,isHash=False,**kwargs):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        super().__init__()\n",
    "        self.padding_idx = 0 if isMasking else None\n",
    "        self.isHash = isHash\n",
    "        if self.isHash:\n",
    "            self.embedding = HashEmbedding(max_words,embedding_size,mask_zero=isMasking,\n",
    "                                           num_buckets=num_buckets,seed=seed,**kwargs)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(max_words,embedding_size,padding_idx=self.padding_idx)\n",
    "        self.reduce = ReduceSum\n",
    "        \n",
    "        self.output_dim = self.embedding.output_dim if isHash else embedding_size\n",
    "        self.fc1 = nn.Linear(self.output_dim, hidden)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden, num_classes)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # Unfortunately has to set weight to 0 even when padding_idx =0\n",
    "        if not self.isHash:\n",
    "            if self.padding_idx is not None:\n",
    "                weights1[0][0,:] = 0\n",
    "            self.embedding.weight = param_from_np(weights1[0])\n",
    "        if self.output_dim == 20:\n",
    "            self.fc1.weight, self.fc1.bias = [param_from_np(w) for w in weights2]\n",
    "            self.fc2.weight, self.fc2.bias = [param_from_np(w) for w in weights3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        m = x.clone() \n",
    "        x = self.embedding(x)\n",
    "        x = self.reduce(x,m) # should be using reduce_sum but basically a phrase is sum of rest (to accept mask)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:02:38.317591Z",
     "start_time": "2018-01-14T14:02:38.259458Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_data(max_words, size_phrase, seed, percTrain = 0.5):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # fetches the data. It contains more than 22k text with the correct labels\n",
    "    twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "    # tokenizes only the first 150 tokens. THe rest is dicarded\n",
    "    # no preprocessing!! should lower case and remove punctuation\n",
    "    data = [nltk.word_tokenize(text)[:size_phrase] for text in twenty_train.data]\n",
    "    # data = [nltk.word_tokenize(text) for text in twenty_train.data]\n",
    "    # hashes all tokens\n",
    "    data_encoded = [[word_encoder(w, max_words) for w in text] for text in data]\n",
    "    max_len = max([len(d) for d in data])\n",
    "\n",
    "    # pad data\n",
    "    # => if sentence is not 150 char long then padds at the end with zeros\n",
    "    data_encoded = [d+[0]*(max_len-len(d)) for d in data_encoded]\n",
    "    \n",
    "    # idx start for testing. Does a 50% split.\n",
    "    idx_test = int(len(data_encoded)*percTrain)\n",
    "    # puts all in a matrix with each row beeing a phrase => nCol = max_len\n",
    "    data_encoded = np.vstack(data_encoded)\n",
    "    # array (col vector) of targets in shape of data_encoded\n",
    "    targets = np.asarray(twenty_train.target, 'int32').reshape((-1,1))\n",
    "    \n",
    "    #return data_encoded, targets, idx_test\n",
    "    np.random.seed(seed)\n",
    "    train = TensorDataset(torch.from_numpy(data_encoded[0:idx_test,:]),\n",
    "                          torch.from_numpy(targets[0:idx_test,:]).type(torch.LongTensor))\n",
    "    np.random.seed(seed)\n",
    "    trainIter=DataLoader(dataset=train,\n",
    "                         batch_size=batchSize,\n",
    "                         shuffle=False)\n",
    "    xTest = Variable(torch.from_numpy(data_encoded[idx_test:,:]),)\n",
    "    yTest = targets[idx_test:,:]\n",
    "    return trainIter, xTest, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:03:07.357695Z",
     "start_time": "2018-01-14T14:02:59.232462Z"
    }
   },
   "outputs": [],
   "source": [
    "trainIter, xTest, yTest = make_data(max_words, size_phrase, seed) # checked output of test is same :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T14:03:22.697599Z",
     "start_time": "2018-01-14T14:03:08.173425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters in model: 2101254\n",
      "Train on 1128 samples, validate on 1129 samples\n",
      "Epoch: 1. Loss: 1.3405081033706665. Acc: 0.42781222320637735.\n",
      "Epoch: 2. Loss: 0.9356852769851685. Acc: 0.6891054030115146.\n",
      "Epoch: 3. Loss: 0.32737886905670166. Acc: 0.8246235606731621.\n",
      "Epoch: 4. Loss: 0.07385215908288956. Acc: 0.9220549158547388.\n",
      "Epoch: 5. Loss: 0.016816945746541023. Acc: 0.9282550930026572.\n",
      "Epoch: 6. Loss: 0.0060875192284584045. Acc: 0.9388839681133747.\n",
      "Epoch: 7. Loss: 0.0034391158260405064. Acc: 0.9397697077059345.\n",
      "Epoch: 8. Loss: 0.0020986858289688826. Acc: 0.9433126660761736.\n",
      "Epoch: 9. Loss: 0.0013713063672184944. Acc: 0.9441984056687334.\n",
      "Epoch: 10. Loss: 0.0009800512343645096. Acc: 0.9459698848538529.\n",
      "[torch.Size([1000000, 2]), torch.Size([5000, 20]), torch.Size([50, 20]), torch.Size([50]), torch.Size([4, 50]), torch.Size([4])]\n",
      "CPU times: user 12.8 s, sys: 1.18 s, total: 14 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = ModelSimple(max_words,embedding_size,num_classes,isHash=True,append_weight=False)\n",
    "criterion=nn.CrossEntropyLoss() # Cross Entropy also computes softmax  !!!\n",
    "optimizer=torch.optim.Adam(model.parameters())\n",
    "\n",
    "np.random.seed(seed)\n",
    "print('Num parameters in model: {}'.format(sum([np.prod(p.shape) for p in model.parameters()])))\n",
    "print(\"Train on 1128 samples, validate on 1129 samples\".format(trainIter.dataset.data_tensor.shape[0],xTest.shape[0]))\n",
    "for epoch in range(1,1+max_epochs):\n",
    "    for x,y in trainIter:\n",
    "        x = Variable(x)\n",
    "        y = Variable(y).squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad() # Reset gradients\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "  \n",
    "    if True:#epoch % 5 == 1 or epoch == 1 or epoch == (max_epochs ):\n",
    "        outputs = model(xTest)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        accuracy = accuracy_score(predicted,yTest)\n",
    "        print(\"Epoch: {}. Loss: {}. Acc: {}.\".format(epoch,loss.data[0],accuracy))\n",
    "        \n",
    "print([p.shape for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T16:31:49.100815Z",
     "start_time": "2018-01-14T16:31:49.089918Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, remove=string.punctuation, isLowercase=True):\n",
    "        self.translator = None if remove is None else str.maketrans('', '', remove)\n",
    "        self.isLowercase = isLowercase\n",
    "        \n",
    "    def __call__(self,txt):\n",
    "        txt = txt.translate(self.translator)\n",
    "        if self.isLowercase:\n",
    "            txt = txt.lower()\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T16:31:49.350050Z",
     "start_time": "2018-01-14T16:31:49.346866Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T16:31:49.717276Z",
     "start_time": "2018-01-14T16:31:49.712587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test1ng'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p('Test1ng!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T19:17:49.000552Z",
     "start_time": "2018-01-14T19:17:48.835690Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AgNews(Dataset):\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 maxWord=1000000,\n",
    "                 maxLength=None,\n",
    "                 transform=None,\n",
    "                 train=True):\n",
    "        r\"\"\"`AG's News <http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html>` dataset.\n",
    "        \n",
    "        Args:\n",
    "            path (string): Root directory of dataset.\n",
    "            maxWord (int,optional): max number of words if hash. If `None` will use a dictionnary.\n",
    "            maxLength (int,optional): max length of a text.\n",
    "            transform (callable,optional) A function/transform that takes in a text and returns a\n",
    "                preprocessed version.\n",
    "            train (bool, optional): If True, creates dataset from ``train.csv`` else ``test.csv``.\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.path = os.path.join(path, \"train.csv\" if self.train else \"test.csv\")\n",
    "        self.maxWord = maxWord\n",
    "        if self.maxWord is None:\n",
    "            self.vocab = dict()\n",
    "        self.maxLen = float(\"inf\") if maxLength is None else maxLength\n",
    "        self.label = None\n",
    "        self.data = None\n",
    "        self.transform = transform\n",
    "        self.load()\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx,:]\n",
    "        y = self.label[idx]\n",
    "        return X, y\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.path, 'r', encoding=\"utf-8\") as f:\n",
    "            nRows = sum(1 for row in f)\n",
    "            label = [None]*nRows\n",
    "            data = [None]*nRows\n",
    "            f.seek(0)\n",
    "            reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "            maxLen = 0\n",
    "            for i, row in enumerate(reader):\n",
    "                label[i] = int(row[0])\n",
    "                txt = ' '.join(row[1:])\n",
    "                if self.transform is not None:\n",
    "                    txt = self.transform(txt)      \n",
    "                if self.maxWord is not None:\n",
    "                    data[i] = torch.Tensor([word_encoder(w,self.maxWord) for i,w in enumerate(txt.split()) if i < self.maxLen])\n",
    "                else:\n",
    "                    l = []\n",
    "                    for counter,w in enumerate(txt.split()):\n",
    "                        if counter >= self.maxLen:\n",
    "                            break\n",
    "                        if w not in self.vocab:\n",
    "                            self.vocab[w] = len(self.vocab)+1\n",
    "                        l.append(self.vocab[w])\n",
    "                    data[i] = torch.Tensor(l)\n",
    "                        \n",
    "                maxLen = max(maxLen,data[i].shape[0])\n",
    "            self.maxLen = min(self.maxLen,maxLen)\n",
    "         \n",
    "        self.data = torch.zeros(nRows, self.maxLen)\n",
    "        for i,tokenIds in enumerate(data):\n",
    "            length = tokenIds.shape[0]\n",
    "            self.data[i,:length] = tokenIds\n",
    "        self.label = torch.LongTensor(label).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T19:17:55.575006Z",
     "start_time": "2018-01-14T19:17:50.336124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.99 s, sys: 124 ms, total: 5.12 s\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = Preprocessor()\n",
    "a = AgNews(\"../data/ag_news_csv\",transform=p,maxLength=None,maxWord=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T19:16:35.913471Z",
     "start_time": "2018-01-14T19:16:23.049124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 150 ms, total: 12.7 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = Preprocessor()\n",
    "a = AgNews(\"../data/ag_news_csv\",transform=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T19:16:37.456904Z",
     "start_time": "2018-01-14T19:16:37.392685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4489931"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.data != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T19:17:55.655726Z",
     "start_time": "2018-01-14T19:17:55.577729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4489931"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.data != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T18:39:11.997248Z",
     "start_time": "2018-01-14T18:39:11.993996Z"
    }
   },
   "outputs": [],
   "source": [
    "trainIter=DataLoader(dataset=a,\n",
    "                         batch_size=batchSize,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T18:40:18.578073Z",
     "start_time": "2018-01-14T18:40:18.561819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      " 7.8965e+05  9.6500e+04  8.5368e+05\n",
      " 4.8642e+05  1.4549e+05  3.2434e+05\n",
      " 2.6022e+05  5.8330e+04  6.1404e+05\n",
      " 8.3122e+05  3.2174e+05  2.6022e+05\n",
      " 2.6022e+05  7.8909e+04  5.2298e+05\n",
      " 2.7182e+05  8.9554e+05  9.7930e+05\n",
      " 3.8800e+05  2.2002e+05  7.1208e+05\n",
      " 3.8219e+05  1.9248e+05  9.6780e+05\n",
      " 6.0277e+05  4.8626e+05  6.5770e+05\n",
      " 7.8965e+05  9.6500e+04  8.5368e+05\n",
      " 2.6022e+05  5.8330e+04  6.1404e+05\n",
      " 1.1515e+05  7.5093e+05  8.4607e+05\n",
      " 2.7258e+04  7.0433e+05  7.8553e+05\n",
      " 1.9609e+04  7.6322e+05  5.6654e+05\n",
      " 8.2904e+05  3.0873e+05  4.8573e+05\n",
      " 2.4158e+05  7.6099e+05  4.2766e+05\n",
      " 7.2542e+05  7.4757e+05  8.4607e+05\n",
      " 4.9571e+05  7.2505e+05  9.0580e+05\n",
      " 4.5790e+05  1.3016e+05  9.4246e+05\n",
      " 6.0414e+05  5.8688e+04  6.5886e+05\n",
      " 1.9609e+04  7.6322e+05  6.9704e+05\n",
      " 6.7354e+05  6.1404e+05  1.3432e+05\n",
      " 1.7647e+05  9.7443e+05  4.9571e+05\n",
      " 4.1838e+05  3.0873e+05  5.9983e+05\n",
      " 3.4844e+04  7.8909e+04  9.0580e+05\n",
      " 1.9356e+05  3.1731e+05  3.3819e+05\n",
      " 1.9609e+04  5.6654e+05  3.1831e+05\n",
      " 1.5346e+05  8.6306e+05  8.4516e+05\n",
      " 3.5845e+04  3.5874e+05  7.4393e+05\n",
      " 4.2538e+05  8.9591e+05  3.4200e+05\n",
      " 4.4265e+05  2.5999e+05  7.4393e+05\n",
      " 2.6945e+05  7.9829e+05  4.9571e+05\n",
      "[torch.FloatTensor of size 32x3]\n",
      "\n",
      "\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "[torch.LongTensor of size 32x1]\n",
      "\n",
      "1\n",
      "\n",
      " 8.9348e+05  8.9026e+05  8.0633e+05\n",
      " 8.9348e+05  9.1491e+05  1.5500e+03\n",
      " 4.6202e+05  2.5915e+05  3.7090e+05\n",
      " 4.0824e+05  7.3528e+05  7.9933e+05\n",
      " 1.9609e+04  7.6322e+05  4.1315e+05\n",
      " 7.2505e+05  8.0934e+05  7.3075e+05\n",
      " 6.5917e+04  1.6988e+05  8.0633e+05\n",
      " 3.2246e+05  9.5362e+05  8.4818e+04\n",
      " 6.3679e+05  8.9540e+05  9.2721e+05\n",
      " 1.8948e+05  3.8585e+05  5.6129e+05\n",
      " 1.4479e+05  2.4085e+05  4.0028e+04\n",
      " 5.9908e+05  8.0633e+05  7.9683e+05\n",
      " 3.2656e+05  5.9908e+05  8.0633e+05\n",
      " 7.2505e+05  4.9429e+05  1.7696e+05\n",
      " 2.5209e+05  8.2803e+05  9.2721e+05\n",
      " 5.2644e+05  6.3393e+05  7.3576e+05\n",
      " 8.4607e+05  1.9869e+05  9.2721e+05\n",
      " 6.5270e+05  7.6310e+03  2.3469e+05\n",
      " 8.6652e+05  5.3765e+04  7.9830e+05\n",
      " 9.3126e+05  8.6608e+05  9.2721e+05\n",
      " 3.1593e+05  6.8059e+05  2.7172e+05\n",
      " 8.2000e+04  2.2890e+05  4.9571e+05\n",
      " 9.2721e+05  2.4380e+05  3.9448e+05\n",
      " 7.7559e+05  2.2737e+05  2.5901e+05\n",
      " 9.3412e+05  9.2721e+05  9.7310e+05\n",
      " 2.3270e+04  8.0633e+05  9.2721e+05\n",
      " 9.2721e+05  4.9429e+05  9.9024e+05\n",
      " 4.5258e+05  3.9448e+05  7.7875e+05\n",
      " 4.1697e+05  9.2721e+05  8.9445e+05\n",
      " 5.1715e+05  1.1297e+05  4.9244e+05\n",
      " 3.3762e+05  3.2421e+05  4.1396e+05\n",
      " 9.2721e+05  9.4007e+04  4.2597e+05\n",
      "[torch.FloatTensor of size 32x3]\n",
      "\n",
      "\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "[torch.LongTensor of size 32x1]\n",
      "\n",
      "2\n",
      "\n",
      " 9.1448e+05  6.2037e+05  8.1159e+05\n",
      " 1.1764e+05  4.5502e+05  9.2721e+05\n",
      " 9.3039e+05  9.1543e+04  5.3464e+05\n",
      " 9.3039e+05  1.1542e+05  5.1728e+05\n",
      " 6.5671e+05  7.6420e+05  8.8344e+05\n",
      " 6.6011e+04  5.9862e+05  8.3548e+05\n",
      " 5.5938e+04  7.1750e+05  6.3353e+05\n",
      " 4.7711e+05  7.5951e+05  1.9609e+04\n",
      " 7.6262e+05  2.5198e+05  8.1495e+05\n",
      " 2.4142e+05  7.4393e+05  6.5369e+05\n",
      " 1.5346e+05  8.0633e+05  9.1110e+05\n",
      " 7.2505e+05  5.3504e+05  3.3890e+05\n",
      " 2.2285e+05  8.8523e+05  7.6229e+05\n",
      " 5.9512e+04  7.5149e+05  9.1151e+05\n",
      " 1.5808e+05  5.0639e+05  3.5876e+05\n",
      " 1.0486e+05  8.0633e+05  4.6889e+05\n",
      " 1.3466e+05  8.0633e+05  9.1179e+05\n",
      " 8.9503e+05  6.6654e+05  4.9429e+05\n",
      " 5.8497e+05  9.2557e+05  8.0849e+05\n",
      " 7.5505e+05  1.8350e+05  5.6695e+05\n",
      " 4.9635e+05  6.8378e+05  5.7560e+05\n",
      " 2.8641e+05  9.3916e+04  7.8222e+05\n",
      " 2.1026e+05  7.8437e+05  8.7088e+05\n",
      " 9.0135e+05  7.3336e+05  8.5995e+05\n",
      " 2.6631e+05  8.0633e+05  2.8641e+05\n",
      " 9.9956e+05  9.9856e+05  4.7200e+03\n",
      " 4.6660e+05  2.2154e+05  5.8711e+05\n",
      " 4.2397e+05  9.6024e+05  8.0633e+05\n",
      " 7.3599e+05  9.5350e+04  6.4766e+05\n",
      " 5.2258e+05  2.6958e+05  6.0056e+05\n",
      " 2.7152e+05  7.2527e+05  9.4799e+05\n",
      " 8.9240e+05  6.3819e+05  1.3401e+05\n",
      "[torch.FloatTensor of size 32x3]\n",
      "\n",
      "\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "[torch.LongTensor of size 32x1]\n",
      "\n",
      "3\n",
      "\n",
      " 4.3776e+05  4.2908e+05  1.9901e+04\n",
      " 8.2000e+04  4.9571e+05  7.2505e+05\n",
      " 9.2461e+05  8.8094e+05  5.0604e+05\n",
      " 7.3599e+05  9.6117e+05  4.1548e+05\n",
      " 5.0862e+05  4.0447e+05  5.8330e+04\n",
      " 9.0299e+05  9.8081e+05  2.4895e+05\n",
      " 5.5354e+05  1.8604e+05  6.0651e+05\n",
      " 9.3906e+05  9.3313e+05  1.5395e+05\n",
      " 6.0651e+05  1.6650e+05  8.9341e+05\n",
      " 2.4564e+05  7.1509e+05  1.2954e+05\n",
      " 3.7718e+05  8.6053e+05  1.0706e+05\n",
      " 7.6441e+05  2.1963e+05  6.7335e+05\n",
      " 9.2798e+04  1.2313e+04  5.3524e+05\n",
      " 4.9429e+05  6.0651e+05  9.1179e+05\n",
      " 6.7883e+04  5.7092e+05  8.1269e+04\n",
      " 5.0238e+05  8.7871e+05  9.0299e+05\n",
      " 8.0206e+05  5.9186e+05  3.3669e+05\n",
      " 3.5826e+05  2.9621e+05  5.9645e+05\n",
      " 1.7450e+04  3.9397e+05  3.9448e+05\n",
      " 8.3816e+05  5.6830e+05  9.6536e+05\n",
      " 1.3747e+05  9.5621e+05  8.5309e+05\n",
      " 5.5655e+05  6.8607e+04  8.6258e+05\n",
      " 8.8094e+05  2.9575e+05  2.9709e+05\n",
      " 5.4089e+05  5.9983e+05  5.9008e+05\n",
      " 1.2977e+05  5.1053e+05  2.3628e+05\n",
      " 1.7489e+04  5.5918e+05  2.8452e+05\n",
      " 4.1681e+05  8.9341e+05  6.7634e+05\n",
      " 8.6676e+05  5.3337e+05  4.9571e+05\n",
      " 6.6166e+05  9.2721e+05  7.2157e+05\n",
      " 4.9324e+05  8.3716e+05  4.7839e+05\n",
      " 9.2721e+05  2.6078e+05  1.5368e+05\n",
      " 7.6229e+05  8.2150e+05  3.9448e+05\n",
      "[torch.FloatTensor of size 32x3]\n",
      "\n",
      "\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "[torch.LongTensor of size 32x1]\n",
      "\n",
      "4\n",
      "\n",
      " 5.2408e+05  4.6660e+05  7.5219e+04\n",
      " 3.0852e+05  3.1831e+05  9.8346e+05\n",
      " 8.1376e+04  3.2825e+05  8.0633e+05\n",
      " 5.6029e+05  7.3081e+05  2.9575e+05\n",
      " 1.8215e+05  9.4853e+05  6.7098e+04\n",
      " 4.9264e+04  7.3971e+04  7.9594e+05\n",
      " 4.5790e+05  1.2718e+05  9.4853e+05\n",
      " 1.0151e+05  3.5902e+05  7.2505e+05\n",
      " 9.1630e+04  4.3948e+05  3.7446e+05\n",
      " 2.5738e+04  6.7782e+05  4.5651e+04\n",
      " 8.8094e+05  1.6988e+05  5.1947e+05\n",
      " 8.2830e+05  3.2656e+05  3.7032e+05\n",
      " 2.2377e+04  3.7562e+05  4.3976e+05\n",
      " 8.5099e+05  3.4673e+05  1.3348e+05\n",
      " 7.9729e+05  1.2745e+05  5.0948e+05\n",
      " 2.4085e+05  1.8654e+05  8.0633e+05\n",
      " 5.8634e+05  3.5162e+05  8.4717e+05\n",
      " 8.9815e+05  5.4019e+05  7.9020e+03\n",
      " 5.6506e+05  8.0633e+05  2.9575e+05\n",
      " 1.5392e+05  3.2153e+04  3.9448e+05\n",
      " 4.9429e+05  4.3374e+05  1.0934e+05\n",
      " 5.0664e+05  5.6506e+05  9.0060e+05\n",
      " 4.0812e+05  9.2654e+05  9.0060e+05\n",
      " 2.9709e+05  1.0934e+05  6.5886e+05\n",
      " 5.9042e+05  8.5309e+05  5.0948e+05\n",
      " 3.3796e+05  6.9960e+05  4.7918e+05\n",
      " 5.1570e+05  8.6948e+05  9.0649e+05\n",
      " 9.2654e+05  7.1610e+05  5.2386e+05\n",
      " 1.0151e+05  3.7063e+05  8.8773e+05\n",
      " 3.4034e+05  8.0633e+05  2.5249e+05\n",
      " 9.3694e+05  7.4056e+05  3.4041e+05\n",
      " 9.9024e+05  3.9448e+05  4.4839e+05\n",
      "[torch.FloatTensor of size 32x3]\n",
      "\n",
      "\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "[torch.LongTensor of size 32x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(trainIter):\n",
    "    print(i)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    \n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(max_words, size_phrase, seed, percTrain = 0.5):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # fetches the data. It contains more than 22k text with the correct labels\n",
    "    twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "    # tokenizes only the first 150 tokens. THe rest is dicarded\n",
    "    # no preprocessing!! should lower case and remove punctuation\n",
    "    data = [nltk.word_tokenize(text)[:size_phrase] for text in twenty_train.data]\n",
    "    # data = [nltk.word_tokenize(text) for text in twenty_train.data]\n",
    "    # hashes all tokens\n",
    "    data_encoded = [[word_encoder(w, max_words) for w in text] for text in data]\n",
    "    max_len = max([len(d) for d in data])\n",
    "\n",
    "    # pad data\n",
    "    # => if sentence is not 150 char long then padds at the end with zeros\n",
    "    data_encoded = [d+[0]*(max_len-len(d)) for d in data_encoded]\n",
    "    \n",
    "    # idx start for testing. Does a 50% split.\n",
    "    idx_test = int(len(data_encoded)*percTrain)\n",
    "    # puts all in a matrix with each row beeing a phrase => nCol = max_len\n",
    "    data_encoded = np.vstack(data_encoded)\n",
    "    # array (col vector) of targets in shape of data_encoded\n",
    "    targets = np.asarray(twenty_train.target, 'int32').reshape((-1,1))\n",
    "    \n",
    "    #return data_encoded, targets, idx_test\n",
    "    np.random.seed(seed)\n",
    "    train = TensorDataset(torch.from_numpy(data_encoded[0:idx_test,:]),\n",
    "                          torch.from_numpy(targets[0:idx_test,:]).type(torch.LongTensor))\n",
    "    np.random.seed(seed)\n",
    "    trainIter=DataLoader(dataset=train,\n",
    "                         batch_size=batchSize,\n",
    "                         shuffle=False)\n",
    "    xTest = Variable(torch.from_numpy(data_encoded[idx_test:,:]),)\n",
    "    yTest = targets[idx_test:,:]\n",
    "    return trainIter, xTest, yTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
