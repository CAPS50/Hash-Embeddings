{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T15:46:52.264023Z",
     "start_time": "2018-01-18T15:46:52.077395Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from evaluate.load.helpers import *\n",
    "from evaluate.load.dataset import *\n",
    "from evaluate.pipeline.model import *\n",
    "from evaluate.pipeline.trainer import *\n",
    "from evaluate.pipeline.embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T15:46:52.307526Z",
     "start_time": "2018-01-18T15:46:52.265965Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_param(mode=\"paper\",isHashEmbedding=True):\n",
    "    return {\"use_hash_embeddings\": isHashEmbedding,\n",
    "            \"hashing_trick\": True,\n",
    "            \"ngram_range\": (1,9),\n",
    "            \"nFeaturesRange\": (4,100),\n",
    "            \"embedding_size\": 20,\n",
    "            \"num_buckets\": 10**6,\n",
    "            \"max_features\": 10**7,\n",
    "            \"max_epochs\": 100,\n",
    "            \"num_hash_functions\": 2,\n",
    "            \"hidden\": 50,\n",
    "            \"seed\": 123,\n",
    "            \"batch_size\": 32,\n",
    "            \"masking\":True,\n",
    "            \"append_weight\":False,\n",
    "            \"validation_size\":0.05,\n",
    "            \"patience\":10,\n",
    "            'cuda':True,\n",
    "            'num_workers':4}\n",
    "            \n",
    "param = get_param()\n",
    "seed = param['seed']\n",
    "max_features = param['max_features']\n",
    "ngram_range = param['ngram_range']\n",
    "use_hash_embeddings = param['use_hash_embeddings']\n",
    "isHashingTrick = param['hashing_trick']\n",
    "num_buckets = param['num_buckets']\n",
    "embedding_size = param['embedding_size']\n",
    "max_epochs = param['max_epochs']\n",
    "masking = param['masking']\n",
    "append_weight = param['append_weight']\n",
    "patience = param['patience']\n",
    "num_hash_functions = param['num_hash_functions']\n",
    "batch_size = param['batch_size']\n",
    "validation_size = param['validation_size']\n",
    "nFeaturesRange = param['nFeaturesRange']\n",
    "isCuda = param['cuda']\n",
    "num_workers = param['num_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T15:47:36.128977Z",
     "start_time": "2018-01-18T15:46:52.310547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 s, sys: 292 ms, total: 43.6 s\n",
      "Wall time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if isHashingTrick:\n",
    "    train = AgNews(nFeaturesRange=nFeaturesRange,train=True,ngramRange=ngram_range,isHashingTrick=True,seed=seed)\n",
    "    test = AgNews(nFeaturesRange=nFeaturesRange,train=False,ngramRange=ngram_range,isHashingTrick=True,seed=seed)\n",
    "else:\n",
    "    train = AgNews(nFeaturesRange=nFeaturesRange,num_words=max_features,train=True,ngram_range=ngram_range,isHashingTrick=False,seed=seed)\n",
    "    test = AgNews(nFeaturesRange=nFeaturesRange,num_words=max_features,train=False,ngram_range=ngram_range,isHashingTrick=False,seed=seed,trainVocab=train.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T15:47:36.134974Z",
     "start_time": "2018-01-18T15:47:36.131757Z"
    }
   },
   "outputs": [],
   "source": [
    "#train, valid = train_valid_load(train,validSize=0.1,isShuffle=True,seed=123,batch_size=batchSize)\n",
    "test = DataLoader(dataset=test,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T15:47:40.949139Z",
     "start_time": "2018-01-18T15:47:36.141801Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(train.classes)\n",
    "model = ModelNoDict(max_features,embedding_size,num_classes,isHash=True,num_buckets=num_buckets)\n",
    "trainer = Trainer(model)\n",
    "callbacks = [EarlyStopping(patience=param['patience'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-18T15:46:54.164Z"
    }
   },
   "outputs": [],
   "source": [
    "# bug with is hash = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-18T15:46:57.185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters in model: 40000092\n",
      "Train on 3563 samples, validate on 188 samples\n",
      "Epoch: 0. Loss: 0.3889523446559906. Acc: 0.7891666666666667.\n",
      "Epoch: 1. Loss: 0.22588536143302917. Acc: 0.8086666666666666.\n",
      "Epoch: 2. Loss: 0.23749275505542755. Acc: 0.8146666666666667.\n",
      "Epoch: 3. Loss: 0.1611558198928833. Acc: 0.8076666666666666.\n",
      "Epoch: 4. Loss: 0.18009354174137115. Acc: 0.8148333333333333.\n",
      "Epoch: 5. Loss: 0.0654757171869278. Acc: 0.8111666666666667.\n",
      "Epoch: 6. Loss: 0.015526359900832176. Acc: 0.8111666666666667.\n",
      "Epoch: 7. Loss: 0.33613213896751404. Acc: 0.8085.\n",
      "Epoch: 8. Loss: 0.010806838981807232. Acc: 0.806.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer(train,callbacks=callbacks,validSize=validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-18T15:46:59.095Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal\n",
    "\n",
    "class HashEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, num_buckets=None, num_hashes=2, train_sharedEmbed=True,\n",
    "                 train_weight=True, append_weight=True, aggregation_mode='sum', mask_zero=False,seed=None):\n",
    "        super(HashEmbedding, self).__init__()\n",
    "        \n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_hashes = num_hashes\n",
    "        defaultNBuckets = (num_embeddings * self.num_hashes)//(self.embedding_dim)\n",
    "        self.num_buckets = num_buckets - 1 if num_buckets is not None else defaultNBuckets\n",
    "        self.train_sharedEmbed = train_sharedEmbed\n",
    "        self.train_weight = train_weight\n",
    "        self.append_weight = append_weight\n",
    "        self.padding_idx = 0 if mask_zero else None\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.importance_weights = nn.Embedding(self.num_embeddings,\n",
    "                                              self.num_hashes)\n",
    "        self.shared_embeddings = nn.Embedding(self.num_buckets + 1,\n",
    "                                            self.embedding_dim,\n",
    "                                            padding_idx=self.padding_idx)\n",
    "        self.hashes = None\n",
    "        \n",
    "        if aggregation_mode == 'sum':\n",
    "            self.aggregate = lambda x: torch.sum(x, dim=-1)\n",
    "        elif aggregation_mode == 'concatenate':\n",
    "            # little bit quicker than permute/contiguous/view\n",
    "            self.aggregate = lambda x: torch.cat([x[:,:,:,i] for i in range(self.num_hashes)], dim=-1) \n",
    "        elif aggregation_mode == 'mean':\n",
    "            self.aggregate = lambda x: torch.mean(x, dim=-1)\n",
    "        else:\n",
    "            raise ValueError('unknown aggregation function {}'.format(aggregation_mode))\n",
    "        \n",
    "        self.output_dim = self.embedding_dim \n",
    "        if aggregation_mode == \"concatenate\":\n",
    "            self.output_dim *= self.num_hashes\n",
    "        if self.append_weight:\n",
    "            self.output_dim += self.num_hashes\n",
    "            \n",
    "        self.reset_parameters()   \n",
    "        \n",
    "    def reset_parameters(self,\n",
    "                        init_shared=lambda x: normal(x,std=0.1),\n",
    "                        init_importance=lambda x: normal(x,std=0.0005)):\n",
    "        \"\"\"Resets the trainable parameters.\"\"\"\n",
    "        def set_constant_row(parameters,iRow=0,value=0):\n",
    "            \"\"\"Return `parameters` with row `iRow` as s constant `value`.\"\"\"\n",
    "            data = parameters.data\n",
    "            data[iRow,:] = value\n",
    "            return torch.nn.Parameter(data,requires_grad=parameters.requires_grad)\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        if self.seed is not None:\n",
    "            torch.manual_seed(self.seed)\n",
    "\n",
    "        self.shared_embeddings.weight = init_shared(self.shared_embeddings.weight)\n",
    "        self.importance_weights.weight = init_importance(self.importance_weights.weight)\n",
    "\n",
    "        if self.padding_idx is not None:\n",
    "            # Unfortunately has to set weight to 0 even when paddingIdx = 0\n",
    "            self.shared_embeddings.weight = set_constant_row(self.shared_embeddings.weight)\n",
    "            self.importance_weights.weight = set_constant_row(self.importance_weights.weight)\n",
    "\n",
    "        self.shared_embeddings.weight.requires_grad = self.train_sharedEmbed\n",
    "        self.importance_weights.weight.requires_grad = self.train_weight\n",
    "\n",
    "        self.hashes = torch.from_numpy((np.random.randint(0, 2 ** 30,\n",
    "                                                          size=(self.num_embeddings, self.num_hashes)\n",
    "                                                         ) % self.num_buckets) + 1 \n",
    "                                      ).type(torch.LongTensor)\n",
    "        \n",
    "    def _idx_hash(self, inputs, maxOutput, mask_zero=True):\n",
    "        r\"\"\"Hash function for integers used to map indices of different sizes.\n",
    "        \n",
    "        Args:\n",
    "            inputs (torch.Tensor): indices to hash.\n",
    "            maxOutput (int): maximum integer to output. I.e size of table to access.\n",
    "            mask_zero (bool,optional): whether should only map zero input to zero.\n",
    "            \n",
    "        To Do:\n",
    "            Should enable :math:`\\hat{D} \\neq D_1`.\n",
    "        \"\"\"  \n",
    "        if mask_zero:\n",
    "            idx_zero = inputs == 0\n",
    "            # shouldn't map non zero vectors to 0\n",
    "            inputs = inputs%(maxOutput-1) + 1\n",
    "            inputs[idx_zero] = 0\n",
    "            return inputs\n",
    "        else:\n",
    "            return inputs%maxOutput\n",
    "            \n",
    "    def forward(self, input):  \n",
    "        idx_hashes = self._idx_hash(input,self.num_embeddings,mask_zero=self.padding_idx is not None)\n",
    "        idx_importance_weights = self._idx_hash(input,self.num_embeddings,mask_zero=False)\n",
    "        idx_shared_embeddings = self.hashes[idx_hashes.data.cpu(),:]\n",
    "        \n",
    "        shared_embedding = torch.stack([self.shared_embeddings(idx_shared_embeddings[:,:,iHash]) \n",
    "                                        for iHash in range(self.num_hashes)], dim=-1)\n",
    "        importance_weight = self.importance_weights(idx_importance_weights)\n",
    "        importance_weight = importance_weight.unsqueeze(-2)\n",
    "        word_embedding = self.aggregate(importance_weight*shared_embedding)\n",
    "        if self.append_weight:\n",
    "            # concateates the vector with the weights\n",
    "            word_embedding = torch.cat([word_embedding,importance_weight.squeeze(-2)],dim=-1) \n",
    "        return word_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=HashEmbedding(10,3,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    2     3\n",
       "    4     3\n",
       "    4     4\n",
       "    1     1\n",
       "    4     1\n",
       "    1     2\n",
       "    1     1\n",
       "    2     3\n",
       "    1     4\n",
       "    1     3\n",
       "[torch.LongTensor of size 10x2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[lambda x : 2*x,lambda x : 3*x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139,\n",
    "    149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227,\n",
    "    229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311,\n",
    "    313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401,\n",
    "    409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491,\n",
    "    499, 503, 509, 521, 523, 541, 547, 557, 563, 569, 571, 577, 587, 593, 599,\n",
    "    601, 607, 613, 617, 619, 631, 641, 643, 647, 653, 659, 661, 673, 677, 683,\n",
    "    691, 701, 709, 719, 727, 733, 739, 743, 751, 757, 761, 769, 773, 787, 797,\n",
    "    809, 811, 821, 823, 827, 829, 839, 853, 857, 859, 863, 877, 881, 883, 887,\n",
    "    907, 911, 919, 929, 937, 941, 947, 953, 967, 971, 977, 983, 991, 997)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1, 11, 13, 17, 19, 23, 29, 31, 37, 41,\n",
    "   43, 47, 53, 59, 61, 67, 71, 73, 79, 83,\n",
    "   89, 97,101,103,107,109,113,121,127,131,\n",
    "  137,139,143,149,151,157,163,167,169,173,\n",
    "  179,181,187,191,193,197,199,209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T12:32:46.584048Z",
     "start_time": "2018-01-18T12:32:46.574547Z"
    }
   },
   "outputs": [],
   "source": [
    "def next_prime(n):\n",
    "    def is_prime(x):\n",
    "        for i in range(2,int(np.sqrt(x))):\n",
    "            if x % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "            \n",
    "    while not is_prime(n):\n",
    "        n += 1\n",
    "    \n",
    "    return n\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T12:32:46.979359Z",
     "start_time": "2018-01-18T12:32:46.974081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000007"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prime(10**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:52:44.661226Z",
     "start_time": "2018-01-18T13:52:44.654662Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:24:34.750394Z",
     "start_time": "2018-01-18T14:24:34.658031Z"
    }
   },
   "outputs": [],
   "source": [
    "class HashFamily():\n",
    "    r\"\"\"Universal hash family as proposed by Carter and Wegman.\n",
    "    \n",
    "    .. math::\n",
    "\n",
    "            \\begin{array}{ll}\n",
    "            h_{{a,b}}(x)=((ax+b)~{\\bmod  ~}p)~{\\bmod  ~}m \\ \\mid p > m\\\\\n",
    "            \\end{array}\n",
    "    \n",
    "    Args:\n",
    "        bins (int): Number of bins to hash to. Better if a prime number.\n",
    "        mask_zero (bool, optional): Whether the 0 input is a special \"padding\" value to mask out.\n",
    "        moduler (int,optional): Temporary hashing. Has to be a prime number.\n",
    "    \"\"\"\n",
    "    def __init__(self,bins,mask_zero=False,moduler=None):\n",
    "        if moduler and moduler <= bins:\n",
    "            raise ValueError(\"p (moduler) should be >> m (buckets)\")\n",
    "            \n",
    "        self.bins = bins \n",
    "        self.moduler = moduler if moduler else self._next_prime(np.random.randint(self.bins+1,2**32))\n",
    "        self.mask_zero = mask_zero\n",
    "        \n",
    "        # do not allow same a and b, as it could mean shifted hashes\n",
    "        self.sampled_a = set()\n",
    "        self.sampled_b = set()\n",
    "    \n",
    "    def _is_prime(self,x):\n",
    "        \"\"\"Naive is prime test.\"\"\"\n",
    "        for i in range(2,int(np.sqrt(x))):\n",
    "            if x % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def _next_prime(self,n):  \n",
    "        \"\"\"Naively gets the next prime larger than n.\"\"\"\n",
    "        while not self._is_prime(n):\n",
    "            n += 1\n",
    "\n",
    "        return n\n",
    "    \n",
    "    def draw_hash(self,a=None,b=None):\n",
    "        \"\"\"Draws a single hash function from the family.\"\"\"\n",
    "        if a is None:\n",
    "            while a is None or a in self.sampled_a:\n",
    "                a = np.random.randint(1, self.moduler-1)\n",
    "                assert len(self.sampled_a) < self.moduler-2, \"please give a bigger moduler\"\n",
    "                \n",
    "            self.sampled_a.add(a)\n",
    "        if b is None:\n",
    "            while b is None or b in self.sampled_b:\n",
    "                b = np.random.randint(0, self.moduler-1)\n",
    "                assert len(self.sampled_b) < self.moduler-1, \"please give a bigger moduler\"\n",
    "                \n",
    "            self.sampled_b.add(b)\n",
    "        \n",
    "        if self.mask_zero:\n",
    "            return lambda x: 0 if x == 0 else ((a*x + b) % self.moduler) % (self.bins-1) + 1\n",
    "        else:\n",
    "            return lambda x: ((a*x + b) % self.moduler) % self.bins \n",
    "    \n",
    "    def draw_hashes(self,n,**kwargs):\n",
    "        \"\"\"Draws n hash function from the family.\"\"\"\n",
    "        return [self.draw_hash() for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:26:47.979862Z",
     "start_time": "2018-01-18T14:26:47.975850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:12:55.379116Z",
     "start_time": "2018-01-18T14:12:48.944954Z"
    }
   },
   "outputs": [],
   "source": [
    "nn = 10**6\n",
    "c = [s for s in string.ascii_letters[:26] + \"   \"]\n",
    "randtext = \"\".join( (np.random.choice(c) for i in range(nn)) )\n",
    "r = [hash(t) for t in randtext.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:24:55.456364Z",
     "start_time": "2018-01-18T14:24:55.449279Z"
    }
   },
   "outputs": [],
   "source": [
    "b = 5\n",
    "\n",
    "h = HashFamily(b,mask_zero=True)\n",
    "hh = h.draw_hashes(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:29:24.773710Z",
     "start_time": "2018-01-18T14:29:24.768715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 4\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3,0,0]).apply_(hh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:37:00.878056Z",
     "start_time": "2018-01-18T14:37:00.871768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1  3\n",
       "  2  2\n",
       "  4  2\n",
       "\n",
       "(1 ,.,.) = \n",
       "  1  1\n",
       "  2  1\n",
       "  4  4\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "\n",
       "(3 ,.,.) = \n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "[torch.FloatTensor of size 4x3x2]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.Tensor([[1,2,3],[4,5,6],[0,0,0],[0,0,0]]).apply_(hhh) for hhh in hh],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:33:51.137031Z",
     "start_time": "2018-01-18T14:33:51.130281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 4\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3,0,0])\n",
    "a.apply_(hh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:33:53.928110Z",
     "start_time": "2018-01-18T14:33:53.924030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 4\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:13:45.216314Z",
     "start_time": "2018-01-18T14:13:44.835023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1089dc048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = 10**3\n",
    "\n",
    "h = HashFamily(b)\n",
    "hh = h.draw_hashes(2)\n",
    "\n",
    "arr2 = np.array([hh[0](i) for i in r])\n",
    "_=plt.hist(arr2,alpha=0.3)\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "arr1 = np.array([hh[1](i)%n for i in r])\n",
    "_=plt.hist(arr1,alpha=0.3)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh[0]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_{{a,b}}(x)=((ax+b)~{\\bmod  ~}p)~{\\bmod  ~}m \\ \\mid p > m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:52:56.339774Z",
     "start_time": "2018-01-18T13:52:56.246901Z"
    }
   },
   "outputs": [],
   "source": [
    "class HashFamily():\n",
    "    r\"\"\"Universal hash family as proposed by Carter and Wegman.\n",
    "    \n",
    "    .. math::\n",
    "\n",
    "            \\begin{array}{ll}\n",
    "            h_{{a,b}}(x)=((ax+b)~{\\bmod  ~}p)~{\\bmod  ~}m \\ \\mid p > m\\\\\n",
    "            \\end{array}\n",
    "    \n",
    "    Args:\n",
    "        bins (int): Number of bins to hash to. Better if a prime number.\n",
    "        moduler (int,optional): Temporary hashing. Has to be a prime number.\n",
    "    \"\"\"\n",
    "    def __init__(self,bins,moduler=None):\n",
    "        if moduler and moduler <= bins:\n",
    "            raise ValueError(\"p (moduler) should be >> m (buckets)\")\n",
    "            \n",
    "        self.bins = bins \n",
    "        self.moduler = moduler if moduler else self._next_prime(np.random.randint(self.bins+1,2**32))\n",
    "        \n",
    "        # do not allow same a and b, as it could mean shifted hashes\n",
    "        self.sampled_a = set()\n",
    "        self.sampled_b = set()\n",
    "    \n",
    "    def _is_prime(self,x):\n",
    "        \"\"\"Naive is prime test.\"\"\"\n",
    "        for i in range(2,int(np.sqrt(x))):\n",
    "            if x % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def _next_prime(self,n):  \n",
    "        \"\"\"Naively gets the next prime larger than n.\"\"\"\n",
    "        while not self._is_prime(n):\n",
    "            n += 1\n",
    "\n",
    "        return n\n",
    "    \n",
    "    def draw_hash(self,a=None,b=None):\n",
    "        \"\"\"Draws a single hash function from the family.\"\"\"\n",
    "        if a is None:\n",
    "            while a is None or a in self.sampled_a:\n",
    "                a = np.random.randint(1, self.moduler-1)\n",
    "                assert len(self.sampled_a) < self.moduler-2, \"please give a bigger moduler\"\n",
    "                \n",
    "            self.sampled_a.add(a)\n",
    "        if b is None:\n",
    "            while b is None or b in self.sampled_b:\n",
    "                b = np.random.randint(0, self.moduler-1)\n",
    "                assert len(self.sampled_b) < self.moduler-1, \"please give a bigger moduler\"\n",
    "                \n",
    "            self.sampled_b.add(b)\n",
    "        \n",
    "        return lambda x: ((a*x + b) % self.moduler) % self.bins\n",
    "    \n",
    "    def draw_hashes(self,n,**kwargs):\n",
    "        \"\"\"Draws n hash function from the family.\"\"\"\n",
    "        return [self.draw_hash() for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:50:21.207840Z",
     "start_time": "2018-01-18T13:50:21.204632Z"
    }
   },
   "outputs": [],
   "source": [
    "h = HashFamily(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:50:21.733787Z",
     "start_time": "2018-01-18T13:50:21.729998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.moduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:50:22.228418Z",
     "start_time": "2018-01-18T13:50:22.224096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h.sampled_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:50:22.713754Z",
     "start_time": "2018-01-18T13:50:22.710816Z"
    }
   },
   "outputs": [],
   "source": [
    "H=h.draw_hashes(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:50:23.198761Z",
     "start_time": "2018-01-18T13:50:23.193053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n",
      "2 0\n"
     ]
    }
   ],
   "source": [
    "for hh in H:\n",
    "    print(hh(27),hh(28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:50:23.860353Z",
     "start_time": "2018-01-18T13:50:23.855999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.sampled_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
